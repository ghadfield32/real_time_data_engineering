{#
    Staging model: DOMAIN events (Iceberg / Flink pipeline variant)
    TODO: Rename this file to stg_<your_domain>_events.sql

    This model reads the Silver Iceberg table (written by Flink) and
    provides a clean, typed, documented interface for downstream dbt models.

    When using the Flink → Iceberg pipeline:
      - Flink already performs column renaming (VendorID → vendor_id)
      - Flink already casts types (BIGINT → INT, DOUBLE → DECIMAL)
      - Flink already filters quality issues (nulls, negatives, out-of-range)
      - Flink already deduplicates (ROW_NUMBER on natural key)
      - Flink already generates the surrogate key (MD5 hash → event_id)

    Therefore, this staging model is a LIGHTWEIGHT PASSTHROUGH — it simply:
      1. Selects from the Iceberg source via iceberg_scan()
      2. Applies a safety-net WHERE clause (in case Flink had an issue)
      3. Re-casts any types that DuckDB reads differently from Iceberg metadata
      4. Documents columns with descriptions for dbt docs

    TODO: Replace all COLUMN_* references with your actual column names.
#}

with source as (
    -- TODO: Replace source name and table name to match sources.yml
    select * from {{ source('raw_DOMAIN', 'raw_DOMAIN_events') }}
),

final as (
    select
        -- Surrogate key (generated by Flink's MD5 hash in 06-silver.sql)
        event_id,

        -- TODO: Add all your Silver columns here.
        -- Group them logically: identifiers, timestamps, measurements, financials.
        -- Example for NYC Taxi:
        --   vendor_id,
        --   pickup_location_id,
        --   dropoff_location_id,
        --   cast(pickup_datetime as timestamp) as pickup_datetime,
        --   cast(dropoff_datetime as timestamp) as dropoff_datetime,
        --   passenger_count,
        --   trip_distance_miles,
        --   round(cast(fare_amount as decimal(10, 2)), 2) as fare_amount,
        --   round(cast(total_amount as decimal(10, 2)), 2) as total_amount,

        -- Partition column (generated by Flink)
        event_date    -- TODO: rename to match your partition column

    from source

    -- Safety net: Flink already filtered these, but guard against empty/null rows
    -- TODO: Update column names to match your primary timestamp
    where event_datetime is not null    -- TODO: replace event_datetime
)

select * from final
