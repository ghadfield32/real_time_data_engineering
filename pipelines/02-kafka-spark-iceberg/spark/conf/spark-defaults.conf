#
# Spark defaults for Pipeline 02: Kafka + Spark + Iceberg
#

# --- Iceberg catalog extensions ---
spark.sql.extensions                              org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.catalog.warehouse                       org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.warehouse.type                  hadoop
spark.sql.catalog.warehouse.warehouse             s3a://warehouse/iceberg
spark.sql.catalog.warehouse.io-impl               org.apache.iceberg.aws.s3.S3FileIO
spark.sql.catalog.warehouse.s3.endpoint            http://minio:9000
spark.sql.catalog.warehouse.s3.access-key-id       minioadmin
spark.sql.catalog.warehouse.s3.secret-access-key   minioadmin
spark.sql.catalog.warehouse.s3.path-style-access   true
spark.sql.catalog.warehouse.client.region           us-east-1

# --- Default catalog (so dbt-spark resolves tables via warehouse catalog) ---
spark.sql.defaultCatalog                          warehouse

# --- S3 / MinIO connectivity ---
spark.hadoop.fs.s3a.endpoint                      http://minio:9000
spark.hadoop.fs.s3a.access.key                    minioadmin
spark.hadoop.fs.s3a.secret.key                    minioadmin
spark.hadoop.fs.s3a.path.style.access             true
spark.hadoop.fs.s3a.impl                          org.apache.hadoop.fs.s3a.S3AFileSystem

# --- Serialization ---
spark.serializer                                  org.apache.spark.serializer.KryoSerializer
spark.sql.parquet.outputTimestampType              TIMESTAMP_MICROS

# --- Adaptive query execution ---
spark.sql.adaptive.enabled                        true
spark.sql.adaptive.coalescePartitions.enabled      true
